{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization_utils  as vu\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/cells/all/train/masks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into blocks of 240x240x4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cells/all/train/masks/ND8_DIV0+4h_20x_noConfinment_6_ch_4_instances_0_9.tif\n",
      "(240, 240)\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(TRAIN_PATH)\n",
    "TEST_FILE = os.path.join(TRAIN_PATH,files[0])\n",
    "print(TEST_FILE)\n",
    "im = io.imread(TEST_FILE)\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faa7e209610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(im, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tifffile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c4e61ca1175c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtifffile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tifffile'"
     ]
    }
   ],
   "source": [
    "import tifffile as tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif.imwrite('temp.tif', data, photometric='minisblack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation \n",
    "\n",
    "In deep learning tasks, a lot of data is need to train DNN model, when the dataset is not big enough, data augmentation should be applied.\n",
    "\n",
    "keras.preprocessing.image.ImageDataGenerator is a data generator, which can feed the DNN with data like : (data,label), it can also do data augmentation at the same time.\n",
    "\n",
    "It is very convenient for us to use keras.preprocessing.image.ImageDataGenerator to do data augmentation by implement image rotation, shift, rescale and so on... see [keras documentation](https://keras.io/preprocessing/image/) for detail.\n",
    "\n",
    "For image segmentation tasks, the image and mask must be transformed **together!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define your data generator\n",
    "\n",
    "If you want to visualize your data augmentation result, set save_to_dir = your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you don't want to do data augmentation, set data_gen_args as an empty dict.\n",
    "#data_gen_args = dict()\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGenerator = trainGenerator(20,'data/membrane/train','image','label',data_gen_args,save_to_dir = \"data/membrane/train/aug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize your data augmentation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 1 classes.\n",
      "Found 0 images belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ad0136214bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#you will see 60 transformed images and their masks in data/membrane/train/aug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyGenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnum_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL/unet/data.py\u001b[0m in \u001b[0;36mtrainGenerator\u001b[0;34m(batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode, mask_color_mode, image_save_prefix, mask_save_prefix, flag_multi_class, num_class, save_to_dir, target_size, seed)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjustData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflag_multi_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL/unet/data.py\u001b[0m in \u001b[0;36madjustData\u001b[0;34m(img, mask, flag_multi_class, num_class)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mnew_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflag_multi_class\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2666\u001b[0m     \"\"\"\n\u001b[1;32m   2667\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2668\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "#you will see 60 transformed images and their masks in data/membrane/train/aug\n",
    "num_batch = 3\n",
    "for i,batch in enumerate(myGenerator):\n",
    "    if(i >= num_batch):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create .npy data\n",
    "\n",
    "If your computer has enough memory, you can create npy files containing all your images and masks, and feed your DNN with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arr,mask_arr = geneTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
    "#np.save(\"data/image_arr.npy\",image_arr)\n",
    "#np.save(\"data/mask_arr.npy\",mask_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
